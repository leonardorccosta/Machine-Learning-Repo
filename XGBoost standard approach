### XGBM approach to standard regression problems

import xgboost as xgb #xgboost package

def call_xgb(X_train, y_train, val_X, val_y, X_test):
  params = {'objective': 'reg:linear'
    'eval_metric': 'rmse',
    'eta': 0.003,
    'max_depth': 10,
    'subsample': 0.4,
    'colsample_bytree': 0.4,
    'alpha':0.002,
    'random_state': 9,
    'silent': True}
  tr_data = xgb.DMatrix(X_train, y_train)
  va_data = xgb.DMatrix(val_X, val_y)
  watchlist = [(tr_data, 'train'), (va_data, 'valid')]
model = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_,
                      rounds = 100, verbose_eval=100)
dtest = xgb.DMatrix(test_X)
xgb_pred_y = model.predict(dtest, ntree_limit=model.best_ntree_limit)
return xgb_pred_y, model_xgb
